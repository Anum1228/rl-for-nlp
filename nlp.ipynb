{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anum1228/rl-for-nlp/blob/main/nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwXtWsv0SI3g",
        "outputId": "3333c4c2-dcef-4bfb-e818-081b20b039fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTit_Uw1Qiqy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/singapore_airlines_reviews.csv')\n",
        "\n",
        "needed_columns = ['rating', 'text']\n",
        "df_final = df[needed_columns]\n",
        "\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YypVFjXmSRWJ"
      },
      "outputs": [],
      "source": [
        "rating_column = df['rating']\n",
        "review_column = df['text']\n",
        "# train_rating, test_rating, train_review, test_review = train_test_split(rating_column, review_column, test_size=0.2, random_state=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3eDmqeTUB6F"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def preprocessing_data(rev):\n",
        "    tokens = word_tokenize(rev.lower())\n",
        "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words and not word.isdigit()]\n",
        "    return ' '.join(filtered_tokens)\n",
        "\n",
        "reviews_preprocessed = [preprocessing_data(review) for review in review_column]\n",
        "\n",
        "\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# vectorizer = TfidfVectorizer(max_features=3000)\n",
        "# train_review_tfidf = vectorizer.fit_transform(train_review)\n",
        "# test_review_tfidf = vectorizer.transform(test_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPZ-CXzvZiJF"
      },
      "outputs": [],
      "source": [
        "train_rating, test_rating, train_review, test_review = train_test_split(rating_column, review_column, test_size=0.2, random_state=50)\n",
        "print(reviews_preprocessed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AO5fIywZ-03p"
      },
      "outputs": [],
      "source": [
        "#use reviews_preprocessed everywhere now\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KF1UYWc7-sb6"
      },
      "outputs": [],
      "source": [
        "max_words = 10000\n",
        "max_len = 150\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(reviews_preprocessed)\n",
        "\n",
        "X_sequences = tokenizer.texts_to_sequences(reviews_preprocessed)\n",
        "X_padded = pad_sequences(X_sequences, maxlen=max_len)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, rating_column, test_size=0.2, random_state=20)\n",
        "\n",
        "print(X_sequences[0])\n",
        "print(X_padded[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LzplN3o-tCs"
      },
      "outputs": [],
      "source": [
        "# making neural network model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=64, input_length=max_len))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "adam_optim = Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer=adam_optim, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=16, validation_split=0.2)\n",
        "# history = history-1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ax5r3SN-zdk"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(y_pred_classes[:10])\n",
        "\n",
        "correct_predictions = 0\n",
        "total_predictions = len(y_test)\n",
        "\n",
        "for i in range(total_predictions):\n",
        "    if y_pred[i] == y_test[i]:\n",
        "        correct_predictions += 1\n",
        "\n",
        "accuracy = correct_predictions / total_predictions\n",
        "\n",
        "print(accuracy*100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMGC/duOBhu9yc+N8lHQnOr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}